## path
data_dir: ../data/dailydialog
pretrained_model_path: ../pretrained_model/bart_large
default_root_dir: /tmp
memory_dir: null
memory_encoding: concate
src: context
trg: response
## training
per_device_train_batch_size: 8
accumulate_grad_batches: 1
per_device_eval_batch_size: 12
lr: 5.0e-3
warmup_steps: 4000
accelerator: gpu
max_epochs: 10
val_check_interval: 1.0 
label_smoothing_factor: 0.1
gradient_clip_val: 1.0 
weight_decay: 0
train_max_src_len: 120
train_max_trg_len: 55
logging_steps: 100
eval_metrics: bleu1
seed: 980406
## generation
gen_max_len: 58
gen_min_len: 5
num_beams: 5
